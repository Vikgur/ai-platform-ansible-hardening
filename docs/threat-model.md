# Модель угроз Ansible Hardening в Sovereign AI

Данный документ фиксирует **модель угроз** для слоя Ansible-hardening в платформе Sovereign AI.

Он отвечает на вопросы:  
– от кого защищаемся  
– что именно защищаем  
– какие угрозы считаются реалистичными  
– какими контролями они закрываются  

Документ опирается на архитектурные допущения из `docs/architecture.md` и служит входной точкой для `docs/compliance-mapping.md`.

# Модели атакующих

В рамках Sovereign AI рассматриваются следующие классы атакующих:

– Внешний злоумышленник  
  Не имеет легитимного доступа, действует через уязвимости или supply chain.

– Компрометированный workload  
  Контейнер или AI-задача, получившие исполнение кода.

– Внутренний пользователь с ограниченными правами  
  Разработчик или оператор без административных полномочий.

– Компрометированный администратор  
  Доступ есть, доверия нет.

– Враждебное или скомпрометированное облако  
  Инфраструктура не считается доверенной по умолчанию.

# Защищаемые активы

Критические активы платформы:

– хосты и Kubernetes-ноды  
– control-plane компоненты  
– GPU и AI-ускорители  
– training data  
– inference data  
– credentials и токены  
– логи и audit-трейлы  

Потеря контроля над любым из них считается критической.

# AI-специфичные угрозы

Для AI-инфраструктур выделяются отдельные классы угроз:

– несанкционированный доступ к GPU  
– утечка training data  
– подмена или отравление данных обучения  
– извлечение inference data  
– side-channel атаки на GPU  
– persistence в драйверах или runtime  

Эти угрозы усиливаются высокой ценностью данных и вычислений.

# Supply Chain атаки

Рассматриваются атаки на цепочку поставки:

– компрометация Ansible-ролей  
– подмена зависимостей в requirements.yml  
– подмена Kubernetes бинарей  
– подмена container runtime  
– вредоносные образы  

Supply chain считается одной из основных поверхностей атаки.

# Lateral Movement

Lateral movement анализируется по отдельным направлениям:

## Node → Node

– перемещение между узлами  
– эскалация через SSH, сервисы, shared secrets  

## Workload → Node

– выход контейнера на хост  
– доступ к kubelet или runtime  
– эксплуатация kernel уязвимостей  

## Workload → Workload

– side-channel атаки  
– сетевое перемещение  
– доступ к общим volumes  

Каждое направление требует отдельных контролей.

# Assumptions и ограничения

Допущения заимствуются из `docs/architecture.md`:

– хосты могут быть скомпрометированы  
– workloads считаются потенциально враждебными  
– ручные изменения запрещены  
– CI является единственным доверенным каналом изменений  

Угрозы вне scope:

– физический доступ к дата-центру  
– аппаратные backdoor’ы  
– атаки уровня nation-state вне модели риска  

# Митигирующие слои

Закрытие угроз обеспечивается несколькими слоями:

– Ansible hardening  
  Базовый контроль узлов и runtime.

– Kubernetes security  
  Ограничение workloads и сетей.

– AI node security  
  Изоляция GPU и AI-специфичных ресурсов.

Подробные меры описаны в:  
– `docs/hardening-baseline.md`  
– `docs/kubernetes-security.md`  
– `docs/ai-node-security.md`  

# Маппинг угроз на контроли

Каждая категория угроз маппится на конкретные контроли:

– OS hardening  
– SSH и access control  
– auditd и логирование  
– container runtime hardening  
– Kubernetes node hardening  
– GPU hardening  

Детальный маппинг приведён в `docs/hardening-baseline.md` и далее используется в `docs/compliance-mapping.md`.

# Использование модели угроз

Данная модель используется для:

– проектирования security-baseline  
– обоснования контролей  
– построения compliance-отчётов  
– оценки изменений Day-2  

Любое изменение архитектуры должно пересматриваться через эту модель угроз.
